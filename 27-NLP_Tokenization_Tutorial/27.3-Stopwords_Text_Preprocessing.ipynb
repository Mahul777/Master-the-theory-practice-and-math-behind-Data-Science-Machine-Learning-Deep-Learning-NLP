{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac11e6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My message, especially to young people, is to have courage to think differently, courage to invent,        to travel the unexplored path, courage to discover the impossible and to conquer the problems and        succeed.', 'These are great qualities that they must work towards.', 'This is my        message to the young people.']\n",
      "['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'These are great qualities that they must work towards.', 'This is my        message to the young people.']\n",
      "['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'great qualiti must work toward .', 'This is my        message to the young people.']\n",
      "['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'great qualiti must work toward .', 'messag young peopl .']\n",
      "sentence ['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'great qualiti must work toward .', 'messag young peopl .']\n",
      "sentence ['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'great qualiti must work toward .', 'messag young peopl .']\n",
      "sentence ['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'great qualiti must work toward .', 'messag young peopl .']\n",
      "lemmatizer ['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'great qualiti must work toward .', 'messag young peopl .']\n",
      "lemmatizer ['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'great qualiti must work toward .', 'messag young peopl .']\n",
      "lemmatizer ['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'great qualiti must work toward .', 'messag young peopl .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sahus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "paragraph = \"My message, especially to young people, is to have courage to think differently, courage to invent,\" \\\n",
    "\"        to travel the unexplored path, courage to discover the impossible and to conquer the problems and \" \\\n",
    "\"       succeed. These are great qualities that they must work towards. This is my \" \\\n",
    "\"       message to the young people.\"\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# üåê Check English Stopwords\n",
    "stopwords.words('english')\n",
    "# ['a',\n",
    "#  'about',\n",
    "#  'above',\n",
    "#  'after',\n",
    "#  'again',\n",
    "#  'against',\n",
    "#  'ain',\n",
    "#  'all',\n",
    "#  'am',\n",
    "#  'an',\n",
    "#  'and',\n",
    "#  'any',\n",
    "#  'are',\n",
    "#  'aren',\n",
    "#  \"aren't\",\n",
    "#  'as',\n",
    "#  'at',\n",
    "#  'be',\n",
    "#  'because',\n",
    "#  'been',\n",
    "#  'before',\n",
    "#  'being',\n",
    "#  'below',\n",
    "#  'between',\n",
    "#  'both',\n",
    "#  'but',\n",
    "#  'by',\n",
    "#  'can',\n",
    "#  'couldn',\n",
    "#  \"couldn't\",\n",
    "#  'd',\n",
    "#  'did',\n",
    "#  'didn',\n",
    "#  \"didn't\",\n",
    "#  'do',\n",
    "#  'does',\n",
    "#  'doesn',\n",
    "#  \"doesn't\",\n",
    "#  'doing',\n",
    "#  'don',\n",
    "#  \"don't\",\n",
    "#  'down',\n",
    "#  'during',\n",
    "#  'each',\n",
    "#  'few',\n",
    "#  'for',\n",
    "#  'from',\n",
    "#  'further',\n",
    "#  'had',\n",
    "#  'hadn',\n",
    "#  \"hadn't\",\n",
    "#  'has',\n",
    "#  'hasn',\n",
    "#  \"hasn't\",\n",
    "#  'have',\n",
    "#  'haven',\n",
    "#  \"haven't\",\n",
    "#  'having',\n",
    "#  'he',\n",
    "#  \"he'd\",\n",
    "#  \"he'll\",\n",
    "#  'her',\n",
    "#  'here',\n",
    "#  'hers',\n",
    "#  'herself',\n",
    "#  \"he's\",\n",
    "#  'him',\n",
    "#  'himself',\n",
    "#  'his',\n",
    "#  'how',\n",
    "#  'i',\n",
    "#  \"i'd\",\n",
    "#  'if',\n",
    "#  \"i'll\",\n",
    "#  \"i'm\",\n",
    "#  'in',\n",
    "#  'into',\n",
    "#  'is',\n",
    "#  'isn',\n",
    "#  \"isn't\",\n",
    "#  'it',\n",
    "#  \"it'd\",\n",
    "#  \"it'll\",\n",
    "#  \"it's\",\n",
    "#  'its',\n",
    "#  'itself',\n",
    "#  \"i've\",\n",
    "#  'just',\n",
    "#  'll',\n",
    "#  'm',\n",
    "#  'ma',\n",
    "#  'me',\n",
    "#  'mightn',\n",
    "#  \"mightn't\",\n",
    "#  'more',\n",
    "#  'most',\n",
    "#  'mustn',\n",
    "#  \"mustn't\",\n",
    "#  'my',\n",
    "#  'myself',\n",
    "#  'needn',\n",
    "#  \"needn't\",\n",
    "#  'no',\n",
    "#  'nor',\n",
    "#  'not',\n",
    "#  'now',\n",
    "#  'o',\n",
    "#  'of',\n",
    "#  'off',\n",
    "#  'on',\n",
    "#  'once',\n",
    "#  'only',\n",
    "#  'or',\n",
    "#  'other',\n",
    "#  'our',\n",
    "#  'ours',\n",
    "#  'ourselves',\n",
    "#  'out',\n",
    "#  'over',\n",
    "#  'own',\n",
    "#  're',\n",
    "#  's',\n",
    "#  'same',\n",
    "#  'shan',\n",
    "#  \"shan't\",\n",
    "#  'she',\n",
    "#  \"she'd\",\n",
    "#  \"she'll\",\n",
    "#  \"she's\",\n",
    "#  'should',\n",
    "#  'shouldn',\n",
    "#  \"shouldn't\",\n",
    "#  \"should've\",\n",
    "#  'so',\n",
    "#  'some',\n",
    "#  'such',\n",
    "#  't',\n",
    "#  'than',\n",
    "#  'that',\n",
    "#  \"that'll\",\n",
    "#  'the',\n",
    "#  'their',\n",
    "#  'theirs',\n",
    "#  'them',\n",
    "#  'themselves',\n",
    "#  'then',\n",
    "#  'there',\n",
    "#  'these',\n",
    "#  'they',\n",
    "#  \"they'd\",\n",
    "#  \"they'll\",\n",
    "#  \"they're\",\n",
    "#  \"they've\",\n",
    "#  'this',\n",
    "#  'those',\n",
    "#  'through',\n",
    "#  'to',\n",
    "#  'too',\n",
    "#  'under',\n",
    "#  'until',\n",
    "#  'up',\n",
    "#  've',\n",
    "#  'very',\n",
    "#  'was',\n",
    "#  'wasn',\n",
    "#  \"wasn't\",\n",
    "#  'we',\n",
    "#  \"we'd\",\n",
    "#  \"we'll\",\n",
    "#  \"we're\",\n",
    "#  'were',\n",
    "#  'weren',\n",
    "#  \"weren't\",\n",
    "#  \"we've\",\n",
    "#  'what',\n",
    "#  'when',\n",
    "#  'where',\n",
    "#  'which',\n",
    "#  'while',\n",
    "#  'who',\n",
    "#  'whom',\n",
    "#  'why',\n",
    "#  'will',\n",
    "#  'with',\n",
    "#  'won',\n",
    "#  \"won't\",\n",
    "#  'wouldn',\n",
    "#  \"wouldn't\",\n",
    "#  'y',\n",
    "#  'you',\n",
    "#  \"you'd\",\n",
    "#  \"you'll\",\n",
    "#  'your',\n",
    "#  \"you're\",\n",
    "#  'yours',\n",
    "#  'yourself',\n",
    "#  'yourselves',\n",
    "#  \"you've\"]\n",
    "\n",
    "# o\tShows list of common English stopwords.\n",
    "# o\t‚ÑπÔ∏è Other languages supported: german, french, arabic, etc.\n",
    "# o\t‚ùó No official Hindi stopwords in NLTK.\n",
    "\n",
    "# üß™ Apply Stopwords + Stemming (Porter Stemmer)\n",
    "# üßæ Steps:\n",
    "# üìë Load the speech paragraph\n",
    "# üß† Tokenize into sentences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = sent_tokenize(paragraph)\n",
    "print(sentences)\n",
    " # ['My message, especially to young people, is to have courage to think differently, courage to invent,    \n",
    " #     to travel the unexplored path, courage to discover the impossible and to conquer the problems and  \n",
    " #       succeed.', 'These are great qualities that they must work towards.', 'This is my   \n",
    " #      message to the young people.']\n",
    "\n",
    "# üîÅ For each sentence:\n",
    "# Tokenize into words\n",
    "# Remove stopwords\n",
    "# Apply Porter Stemmer\n",
    "# Join the words back into a sentence\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = word_tokenize(sentences[i]) #lst of words\n",
    "    words = [stemmer.stem(word) for word in words if word.lower() not in set(stopwords.words('english'))] #removing the word frpm para\n",
    "    sentences[i] = ' '.join(words)  #After processing, all the stemmed, filtered words are joined back into a sentence string using ' '.join()\n",
    "    print(sentences)\n",
    "#     ['My message, especially to young people, is to have courage to think differently, courage to invent,        to travel the unexplored path, courage to discover the impossible and to conquer the problems and        succeed.', 'These are great qualities that they must work towards.', 'This is my        message to the young people.']\n",
    "# ['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'These are great qualities that they must work towards.', 'This is my        message to the young people.']\n",
    "# ['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'great qualiti must work toward .', 'This is my        message to the young people.']\n",
    "# ['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'great qualiti must work toward .', 'messag young peopl .']\n",
    "\n",
    "\n",
    "# ‚ùÑÔ∏è Apply Stopwords + Snowball Stemmer (Improved)\n",
    "# ‚úÖ Why Snowball is better:\n",
    "# ‚Ä¢\tMakes all words lowercase\n",
    "# ‚Ä¢\tBetter stemming logic than Porter\n",
    "# üí° Code:\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowballstemmer = SnowballStemmer('english')\n",
    "for i in range(len(sentences)):\n",
    "    words = word_tokenize(sentences[i]) #lst of words\n",
    "    words = [snowballstemmer.stem(word) for word in words if word.lower() not in set(stopwords.words('english'))] #removing the word frpm para\n",
    "    sentences[i] = ' '.join(words)  #After processing, all the stemmed, filtered words are joined back into a sentence string using ' '.join()\n",
    "    print(\"sentence\",sentences)\n",
    "# ['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'great qualiti must work toward .', 'messag young peopl .']\n",
    "# ['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'great qualiti must work toward .', 'messag young peopl .']\n",
    "# ['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'great qualiti must work toward .', 'messag young peopl .']\n",
    "\n",
    "\n",
    "# üçã Apply Stopwords + Lemmatization\n",
    "# ‚úÖ Why Lemmatization is better:\n",
    "# ‚Ä¢\tReturns real words (dictionary form)\n",
    "# ‚Ä¢\tSlower but more accurate\n",
    "# üí° Code:\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = word_tokenize(sentences[i])\n",
    "    words = [lemmatizer.lemmatize(word, pos='v') for word in words]\n",
    "    sentences[i] = ' '.join(words)\n",
    "    print(\"lemmatizer\", sentences)\n",
    "    \n",
    "# lemmatizer ['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'great qualiti must work toward .', 'messag young peopl .']\n",
    "# lemmatizer ['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'great qualiti must work toward .', 'messag young peopl .']\n",
    "# lemmatizer ['messag , especi young peopl , courag think differ , courag invent , travel unexplor path , courag discov imposs conquer problem succeed .', 'great qualiti must work toward .', 'messag young peopl .']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
