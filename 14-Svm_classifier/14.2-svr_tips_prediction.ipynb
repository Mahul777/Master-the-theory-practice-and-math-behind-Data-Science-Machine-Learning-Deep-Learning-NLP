{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6374b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4\n",
      "R2 Score: 0.46028114561159283\n",
      "MAE: 4.1486423210190235\n",
      "Best Parameters: {'C': 10, 'epsilon': 1, 'kernel': 'linear'}\n",
      "R2 Score: 0.5354352825562995\n",
      "MAE: 3.9299196504238987\n"
     ]
    }
   ],
   "source": [
    "# ðŸ§­ Step-by-Step Process\n",
    "# 1. Load the Data\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('tips')\n",
    "print(df.head())\n",
    "\n",
    "# | Index | Total Bill | Tip  | Sex    | Smoker | Day | Time   | Size |\n",
    "# | ----- | ---------- | ---- | ------ | ------ | --- | ------ | ---- |\n",
    "# | 0     | 16.99      | 1.01 | Female | No     | Sun | Dinner | 2    |\n",
    "# | 1     | 10.34      | 1.66 | Male   | No     | Sun | Dinner | 3    |\n",
    "# | 2     | 21.01      | 3.50 | Male   | No     | Sun | Dinner | 3    |\n",
    "# | 3     | 23.68      | 3.31 | Male   | No     | Sun | Dinner | 2    |\n",
    "# | 4     | 24.59      | 3.61 | Female | No     | Sun | Dinner | 4    |\n",
    "\n",
    "# âœ… Explanation: We load the \"tips\" dataset, which contains info like \n",
    "# total_bill, tip, sex, smoker, day, Time,Size.\n",
    "\n",
    "# 2. Define Independent & Dependent Features\n",
    "X = df.drop('total_bill', axis=1) # removing the TOtal Bill Column and rest is saved ion X as Independent Feature\n",
    "y = df[\"total_bill\"] # y is Dependent Feature \n",
    "# âœ… Explanation:\n",
    "# â€¢\tX: All features except total_bill\n",
    "# â€¢\ty: Target variable we want to predict (total bill)\n",
    "\n",
    "# 3. Train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)\n",
    "# âœ… Explanation:\n",
    "# Split the dataset so we can train on one part and test on another to avoid overfitting (this prevents data leakage).\n",
    "\n",
    "df['sex'].value_counts()\n",
    "# sex\n",
    "# Male      157\n",
    "# Female     87\n",
    "# Name: count, dtype: int64\n",
    "\n",
    "df['smoker'].value_counts()\n",
    "# smoker\n",
    "# No     151\n",
    "# Yes     93\n",
    "# Name: count, dtype: int64\n",
    "\n",
    "df['day'].value_counts()\n",
    "# day\n",
    "# Sat     87\n",
    "# Sun     76\n",
    "# Thur    62\n",
    "# Fri     19\n",
    "# Name: count, dtype: int64\n",
    "\n",
    "df['time'].value_counts()\n",
    "# time\n",
    "# Dinner    176\n",
    "# Lunch      68\n",
    "# Name: count, dtype: int64\n",
    "\n",
    "\n",
    "\n",
    "# 4. Label Encoding for Binary Categorical Columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 3 binary category\n",
    "le_sex = LabelEncoder()\n",
    "le_smoker = LabelEncoder()\n",
    "le_time = LabelEncoder()\n",
    "\n",
    "\n",
    "# Encode 'sex' column in training data: converts 'Male'/'Female' to 0/1\n",
    "X_train['sex'] = le_sex.fit_transform(X_train['sex'])\n",
    "# Encode 'smoker' column in training data: converts 'Yes'/'No' to 1/0\n",
    "X_train['smoker'] = le_smoker.fit_transform(X_train['smoker'])\n",
    "# Encode 'time' column in training data: converts 'Lunch'/'Dinner' to 0/1\n",
    "X_train['time'] = le_time.fit_transform(X_train['time'])\n",
    "\n",
    "\n",
    "X_train.head()\n",
    "# | Index | tip  | sex | smoker | day | time | size |\n",
    "# | ----- | ---- | --- | ------ | --- | ---- | ---- |\n",
    "# | 58    | 1.76 | 1   | 1      | Sat | 0    | 2    |\n",
    "# | 1     | 1.66 | 1   | 0      | Sun | 0    | 3    |\n",
    "# | 2     | 3.50 | 1   | 0      | Sun | 0    | 3    |\n",
    "# | 68    | 2.01 | 1   | 0      | Sat | 0    | 2    |\n",
    "# | 184   | 3.00 | 1   | 1      | Sun | 0    | 2    |\n",
    "\n",
    "# Now same transformation done with test dataset\n",
    "X_test['sex'] = le_sex.transform(X_test['sex'])\n",
    "X_test['smoker'] = le_smoker.transform(X_test['smoker'])\n",
    "X_test['time'] = le_time.transform(X_test['time'])\n",
    "\n",
    "X_test.head()\n",
    "# | Index | tip  | sex | smoker | day | time | size |\n",
    "# | ----- | ---- | --- | ------ | --- | ---- | ---- |\n",
    "# | 162   | 2.00 | 0   | 0      | Sun | 0    | 3    |\n",
    "# | 60    | 3.21 | 1   | 1      | Sat | 0    | 2    |\n",
    "# | 61    | 2.00 | 1   | 1      | Sat | 0    | 2    |\n",
    "# | 63    | 3.76 | 1   | 1      | Sat | 0    | 4    |\n",
    "# | 69    | 2.09 | 1   | 1      | Sat | 0    | 2    |\n",
    "\n",
    "# # âœ… Explanation:\n",
    "# # â€¢\tFor binary features like sex, smoker, and time, we use Label Encoding (convert to 0/1).\n",
    "# # â€¢\tApply .fit_transform() on training data and .transform() on test data to avoid leakage.\n",
    "\n",
    "# Since day has more than 2 category \n",
    "# The column 'day' contains categories like 'Sun', 'Sat', 'Thur', 'Fri'. \n",
    "# Since machine learning models can't handle text directly, we convert them into numeric dummy columns.\n",
    "\n",
    "# For example:\n",
    "# 'Sun' â†’ [0, 0, 0]\n",
    "# 'Sat' â†’ [1, 0, 0]\n",
    "# 'Thur' â†’ [0, 1, 0]\n",
    "# 'Fri' â†’ [0, 0, 1]\n",
    "# 5. One Hot Encoding for 'day' Feature\n",
    "\n",
    "#ColumnTransformer applies transformations to specific columns ('day' in this case).\n",
    "# 'onehot' â†’ name of the transformer.\n",
    "# OneHotEncoder(drop='first') â†’ converts 'day' into multiple binary columns and drops the first category to avoid multicollinearity.\n",
    "# ['day'] â†’ apply only to the 'day' column.\n",
    "# remainder='passthrough' â†’ keep all other columns (like tip, sex, smoker, etc.) as it is.\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[('onehot', OneHotEncoder(drop='first'), ['day'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_train = ct.fit_transform(X_train)\n",
    "X_train\n",
    "X_test = ct.transform(X_test)\n",
    "X_test\n",
    "\n",
    "# 6. Apply Support Vector Regression (SVR)\n",
    "\n",
    "# We use SVR when we want a powerful and flexible regression model that can handle non-linearity,\n",
    "#  outliers, and small datasets effectively.\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svr.predict(X_test)\n",
    "# âœ… Explanation:\n",
    "# Train the SVR model on the processed training data and predict on the test data.\n",
    "\n",
    "# 7. Evaluate the Model\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "# âœ… Explanation:\n",
    "# â€¢\tR2 Score: Measures how well the model predicts (closer to 1 is better)\n",
    "# â€¢\tMAE: Average of errors (lower is better)\n",
    "\n",
    "# 8. Hyperparameter Tuning using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'epsilon': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid, cv=5, refit=True)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "# âœ… Explanation:\n",
    "# Try different SVR parameters (kernel, C, epsilon) using GridSearchCV to find the best model.\n",
    "\n",
    "# 9. Predict Using Best Model\n",
    "grid_preds = grid.predict(X_test)\n",
    "\n",
    "print(\"R2 Score:\", r2_score(y_test, grid_preds))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, grid_preds))\n",
    "\n",
    "# R2 Score: 0.46028114561159283\n",
    "# MAE: 4.1486423210190235\n",
    "# Best Parameters: {'C': 10, 'epsilon': 1, 'kernel': 'linear'}\n",
    "# R2 Score: 0.5354352825562995\n",
    "# MAE: 3.9299196504238987\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
